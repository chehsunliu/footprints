{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2020 - Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TextIO\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "available_metrics = [\n",
    "    'timestamp', 'AMB_TEMP', 'CH4', 'CO', 'NMHC', 'NO', 'NO2', 'NOx', 'O3', 'PM10', 'PM2.5', 'RAINFALL', 'RH', 'SO2', 'THC', 'WD_HR', 'WIND_DIREC', 'WIND_SPEED'\n",
    "]\n",
    "\n",
    "\n",
    "def _append_transformed_data(f: TextIO, lines: List[bytes], with_headers: bool):\n",
    "    data = [{} for hour in range(24)]\n",
    "    \n",
    "    for line in lines:\n",
    "        columns: List[bytes] = line.strip().split(b\",\")\n",
    "            \n",
    "        column_date: str = columns[0].decode()\n",
    "        column_metric: str = columns[2].decode()\n",
    "        column_values: List[str] = [v.decode() for v in columns[3:]]\n",
    "        assert len(column_values) == 24\n",
    "        \n",
    "        for hour, item in enumerate(data):\n",
    "            item[\"timestamp\"] = int(datetime.strptime(f\"{column_date} {hour}\", \"%Y/%m/%d %H\").timestamp())\n",
    "            \n",
    "        for hour, column_value in enumerate(column_values):\n",
    "            try:\n",
    "                value = float(column_value)\n",
    "            except ValueError:\n",
    "                assert column_value == \"NR\"\n",
    "                value = 0\n",
    "            data[hour][column_metric] = value\n",
    "    \n",
    "    metrics = list(data[0].keys())\n",
    "    if with_headers:\n",
    "        f.write(\",\".join(metrics) + \"\\n\")\n",
    "    for item in sorted(data, key=lambda x: x[\"timestamp\"]):\n",
    "        features = [str(item[metric]) for metric in metrics]\n",
    "        f.write(\",\".join(features) + \"\\n\")\n",
    "\n",
    "\n",
    "def transform(*, input_path: str, output_path: str):\n",
    "    with open(input_path, \"rb\") as input_file, open(output_path, \"w\") as output_file:\n",
    "        lines = []\n",
    "        for i, line in enumerate(input_file):\n",
    "            # Skip header.\n",
    "            if i == 0:\n",
    "                continue\n",
    "            \n",
    "            if i % 18 != 0:\n",
    "                lines.append(line)\n",
    "            else:\n",
    "                _append_transformed_data(output_file, lines, i == 18)\n",
    "                lines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(input_path=\"train.csv\", output_path=\"/tmp/train_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,AMB_TEMP,CH4,CO,NMHC,NO,NO2,NOx,O3,PM10,PM2.5,RAINFALL,RH,SO2,THC,WD_HR,WIND_DIREC,WIND_SPEED\n",
      "1388505600,14.0,1.8,0.51,0.2,0.9,16.0,17.0,16.0,56.0,26.0,0,77.0,1.8,2.0,37.0,35.0,1.4\n",
      "1388509200,14.0,1.8,0.41,0.15,0.6,9.2,9.8,30.0,50.0,39.0,0,68.0,2.0,2.0,80.0,79.0,1.8\n",
      "cat: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!cat /tmp/train_transformed.csv | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1.3885056e+09, 14., 1.8, 0.51, 0.2 , 0.9, 16. , 17. , 16., 56., 26., 0., 77., 1.8, 2. ,  37.,  35. , 1.4),\n",
       "       (1.3885092e+09, 14., 1.8, 0.41, 0.15, 0.6,  9.2,  9.8, 30., 50., 39., 0., 68., 2. , 2. ,  80.,  79. , 1.8),\n",
       "       (1.3885128e+09, 14., 1.8, 0.39, 0.13, 0.5,  8.2,  8.7, 27., 48., 36., 0., 67., 1.7, 2. ,  57.,   2.4, 1. ),\n",
       "       ...,\n",
       "       (1.4190804e+09, 13., 1.8, 0.51, 0.16, 1.5, 13. , 15. , 13., 50., 17., 0., 82., 2.3, 1.9, 114., 118. , 1.5),\n",
       "       (1.4190840e+09, 13., 1.8, 0.57, 0.19, 1.1, 13. , 14. , 13., 32., 24., 0., 84., 2.3, 2. , 108., 100. , 2. ),\n",
       "       (1.4190876e+09, 13., 1.8, 0.56, 0.19, 1.3, 14. , 15. , 13., 22., 29., 0., 84., 2.3, 2. , 109., 105. , 2. )],\n",
       "      dtype=[('timestamp', '<f8'), ('AMB_TEMP', '<f8'), ('CH4', '<f8'), ('CO', '<f8'), ('NMHC', '<f8'), ('NO', '<f8'), ('NO2', '<f8'), ('NOx', '<f8'), ('O3', '<f8'), ('PM10', '<f8'), ('PM25', '<f8'), ('RAINFALL', '<f8'), ('RH', '<f8'), ('SO2', '<f8'), ('THC', '<f8'), ('WD_HR', '<f8'), ('WIND_DIREC', '<f8'), ('WIND_SPEED', '<f8')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "named_features = np.genfromtxt(\"/tmp/train_transformed.csv\", delimiter=\",\", names=True)\n",
    "named_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = named_features.view((np.float64, len(named_features.dtype.names)))\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5759, 18)\n",
      "(5759, 1)\n"
     ]
    }
   ],
   "source": [
    "offsets = 0\n",
    "\n",
    "cont_features = features\n",
    "for offset in range(1, offsets + 1):\n",
    "    cont_features = np.concatenate(\n",
    "        (\n",
    "            cont_features,\n",
    "            np.concatenate(\n",
    "                (\n",
    "                    features[offset:],\n",
    "                    np.array([[np.nan] * len(named_features.dtype.names)] * offset),\n",
    "                ),\n",
    "                axis=0,\n",
    "            ),\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "cont_features = cont_features[:-(offsets + 1)]\n",
    "labels = named_features[\"PM25\"][:,np.newaxis][offsets + 1:]\n",
    "print(cont_features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
