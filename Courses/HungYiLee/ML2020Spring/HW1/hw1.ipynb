{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reorganization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traininf Data Transformation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def _partial_transpose(output_path: str, lines: List[bytes], is_initial_turn: bool) -> None:\n",
    "    assert len(lines) == 18\n",
    "    output_mode: str =  \"w\" if is_initial_turn else \"a\"\n",
    "    data = [{} for _ in range(24)]\n",
    "\n",
    "    with open(output_path, output_mode) as f:\n",
    "        for line in lines:\n",
    "            raw_date, _, raw_metric, raw_values = line.strip().split(b\",\", 3)\n",
    "            \n",
    "            date: str = raw_date.decode()\n",
    "            metric: str = raw_metric.decode()\n",
    "            values: List[str] = [raw_value.decode() for raw_value in raw_values.split(b\",\")]\n",
    "            assert len(values) == 24\n",
    "            \n",
    "            for hour, _ in enumerate(data):\n",
    "                timestamp: int = int(datetime.strptime(date + f\" {hour}\", \"%Y/%m/%d %H\").timestamp())\n",
    "                data[hour][\"timestamp\"] = str(timestamp)\n",
    "            \n",
    "            for hour, value in enumerate(values):\n",
    "                data[hour][metric] = (\"0\" if value == \"NR\" else value)\n",
    "                \n",
    "        metrics: List[str] = sorted(data[0].keys())\n",
    "        if is_initial_turn:\n",
    "            f.write(\",\".join(metrics) + \"\\n\")\n",
    "            \n",
    "        for item in data:\n",
    "            f.write(\",\".join([item[metric] for metric in metrics]) + \"\\n\")\n",
    "\n",
    "\n",
    "def reorganize_training_data(input_path: str, output_path: str) -> None:\n",
    "    with open(input_path, \"rb\") as f:\n",
    "        lines: List[bytes] = []\n",
    "        \n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:  # Skip the header line\n",
    "                continue\n",
    "            \n",
    "            lines.append(line)\n",
    "            \n",
    "            if i % 18 == 0:\n",
    "                _partial_transpose(output_path, lines, i == 18)\n",
    "                lines = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorganize_training_data(\"./train.csv\", \"./train-transformed1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMB_TEMP,CH4,CO,NMHC,NO,NO2,NOx,O3,PM10,PM2.5,RAINFALL,RH,SO2,THC,WD_HR,WIND_DIREC,WIND_SPEED,WS_HR,timestamp\n",
      "14,1.8,0.51,0.2,0.9,16,17,16,56,26,0,77,1.8,2,37,35,1.4,0.5,1388505600\n",
      "14,1.8,0.41,0.15,0.6,9.2,9.8,30,50,39,0,68,2,2,80,79,1.8,0.9,1388509200\n",
      "14,1.8,0.39,0.13,0.5,8.2,8.7,27,48,36,0,67,1.7,2,57,2.4,1,0.6,1388512800\n",
      "13,1.8,0.37,0.12,1.7,6.9,8.6,23,35,35,0,74,1.6,1.9,76,55,0.6,0.3,1388516400\n",
      "cat: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!cat ./train-transformed1.csv | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Transformation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(14., 1.8, 0.51, 0.2 , 0.9, 16. , 17. , 16., 56., 26., 0., 77., 1.8, 2. ,  37.,  35. , 1.4, 0.5, 1.3885056e+09),\n",
       "       (14., 1.8, 0.41, 0.15, 0.6,  9.2,  9.8, 30., 50., 39., 0., 68., 2. , 2. ,  80.,  79. , 1.8, 0.9, 1.3885092e+09),\n",
       "       (14., 1.8, 0.39, 0.13, 0.5,  8.2,  8.7, 27., 48., 36., 0., 67., 1.7, 2. ,  57.,   2.4, 1. , 0.6, 1.3885128e+09),\n",
       "       ...,\n",
       "       (13., 1.8, 0.51, 0.16, 1.5, 13. , 15. , 13., 50., 17., 0., 82., 2.3, 1.9, 114., 118. , 1.5, 1.6, 1.4190804e+09),\n",
       "       (13., 1.8, 0.57, 0.19, 1.1, 13. , 14. , 13., 32., 24., 0., 84., 2.3, 2. , 108., 100. , 2. , 1.8, 1.4190840e+09),\n",
       "       (13., 1.8, 0.56, 0.19, 1.3, 14. , 15. , 13., 22., 29., 0., 84., 2.3, 2. , 109., 105. , 2. , 2. , 1.4190876e+09)],\n",
       "      dtype=[('AMB_TEMP', '<f8'), ('CH4', '<f8'), ('CO', '<f8'), ('NMHC', '<f8'), ('NO', '<f8'), ('NO2', '<f8'), ('NOx', '<f8'), ('O3', '<f8'), ('PM10', '<f8'), ('PM25', '<f8'), ('RAINFALL', '<f8'), ('RH', '<f8'), ('SO2', '<f8'), ('THC', '<f8'), ('WD_HR', '<f8'), ('WIND_DIREC', '<f8'), ('WIND_SPEED', '<f8'), ('WS_HR', '<f8'), ('timestamp', '<f8')])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data = np.genfromtxt(\"./train-transformed1.csv\", delimiter=\",\", names=True)\n",
    "original_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMB_TEMP,CH4,CO,NMHC,NO,NO2,NOx,O3,PM10,PM25,RAINFALL,RH,SO2,THC,WD_HR,WIND_DIREC,WIND_SPEED,WS_HR,timestamp\n"
     ]
    }
   ],
   "source": [
    "print(\",\".join(original_training_data.dtype.names))\n",
    "fields = [\n",
    "    \"AMB_TEMP\",\n",
    "    \"CH4\",\n",
    "    \"CO\",\n",
    "    \"NMHC\",\n",
    "    \"NO\",\n",
    "    \"NO2\",\n",
    "    \"NOx\",\n",
    "    \"O3\",\n",
    "    \"PM10\",\n",
    "    \"PM25\",\n",
    "    \"RAINFALL\",\n",
    "    \"RH\",\n",
    "    \"SO2\",\n",
    "    \"THC\",\n",
    "    \"WD_HR\",\n",
    "    \"WIND_DIREC\",\n",
    "    \"WIND_SPEED\",\n",
    "    \"WS_HR\",\n",
    "#     \"timestamp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_data(original_data, fields):\n",
    "    data = original_data[fields[0]][:, np.newaxis]\n",
    "\n",
    "    for field in fields[1:]:\n",
    "        data = np.concatenate([data, original_data[field][:, np.newaxis]], axis=1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "training_data = to_data(original_training_data, fields)\n",
    "norm_mean = np.mean(training_data, axis=0)\n",
    "norm_std = np.std(training_data, axis=0)\n",
    "\n",
    "training_data = (training_data - norm_mean) / norm_std\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_X(hours, data, shrink: bool = True):\n",
    "    assert 1 <= hours\n",
    "\n",
    "    X_prime = data\n",
    "    for h in range(hours - 1):\n",
    "        X_prime = np.concatenate((X_prime[:-1], data[h+1:]), axis=1)\n",
    "\n",
    "    if shrink:\n",
    "        X = X_prime[:-1]\n",
    "    else:\n",
    "        X = X_prime\n",
    "\n",
    "    n, k = X.shape\n",
    "\n",
    "    return np.concatenate((np.ones(n).reshape(n, 1), X), axis=1)\n",
    "    \n",
    "hours = 5\n",
    "X = to_X(hours, training_data)\n",
    "\n",
    "y = original_training_data[\"PM25\"][hours:]\n",
    "y_mean = np.mean(y, axis=0)\n",
    "y_std = np.std(y, axis=0)\n",
    "y = (y - y_mean) / y_std\n",
    "\n",
    "n, k = X.shape\n",
    "k -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = (5755, 91)\n",
      "y = (5755,)\n",
      "(n, k) = (5755, 90)\n"
     ]
    }
   ],
   "source": [
    "print(\"X =\", X.shape)\n",
    "print(\"y =\", y.shape)\n",
    "print(\"(n, k) =\", (n, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.908395013537785\n",
      "26.90839387101642\n",
      "26.908392728732643\n",
      "26.908391586686335\n",
      "26.908390444877387\n",
      "26.908389303305686\n",
      "26.908388161971114\n",
      "26.90838702087356\n",
      "26.908385880012908\n",
      "[ 4.78986410e-04 -2.00409483e-02 -5.25649509e-03  2.67039657e-03\n",
      "  1.61605455e-02 -4.75526381e-05 -3.67574463e-02  1.81290002e-02\n",
      " -1.61448857e-02  6.56629616e-03 -5.69949620e-02 -6.10500806e-03\n",
      " -3.14106009e-02 -3.96711045e-03 -5.61489569e-03  2.45217705e-03\n",
      "  3.92320863e-03 -5.16764080e-03 -6.47697968e-03  2.23977919e-03\n",
      "  3.04246122e-03 -9.22599105e-04 -1.94274515e-02 -1.35821100e-02\n",
      "  1.40568038e-03  6.01078276e-03 -2.68291485e-02 -2.75904301e-02\n",
      "  3.71625226e-01  6.47698290e-03  3.85910704e-02  5.62277493e-03\n",
      "  1.43394944e-02  1.08453790e-02  1.61016332e-03 -7.97043186e-03\n",
      "  1.86265208e-02 -4.11108802e-03 -1.16704155e-02 -8.17733166e-03\n",
      " -1.62026470e-03  6.60860394e-03 -2.19083379e-02 -4.71226532e-03\n",
      " -3.04594658e-02  2.88916252e-02 -4.44104038e-01  1.81868684e-03\n",
      " -6.97173251e-02 -1.06538157e-02  1.00497004e-02 -1.62053176e-02\n",
      " -2.44339424e-04 -4.75128266e-03  2.78817985e-04 -5.34534479e-02\n",
      "  5.10008334e-03  5.67315586e-03  1.14256134e-02  9.00455520e-03\n",
      " -5.43465971e-02  1.98548348e-02 -1.48085364e-02  3.35680249e-04\n",
      "  1.06984600e-02 -3.92016227e-03  1.62372728e-02  1.50730338e-02\n",
      " -2.42745553e-02  7.05966318e-03 -1.46450705e-02 -5.35162898e-03\n",
      " -1.42256143e-02  7.26426127e-02  3.28494247e-02  2.25589439e-02\n",
      "  3.81770006e-03 -2.17559209e-02  6.22352737e-02  5.74389944e-02\n",
      "  1.13714883e-01  6.59203710e-02  9.32943997e-01 -1.04522484e-02\n",
      "  1.87461677e-02  1.38795846e-02 -7.76488552e-03  1.38527825e-03\n",
      "  7.06596868e-04 -1.81128286e-03  7.69519909e-03]\n"
     ]
    }
   ],
   "source": [
    "bound = 10000\n",
    "\n",
    "w_init = np.zeros(k + 1)\n",
    "\n",
    "w = w_init\n",
    "for b in range(bound):\n",
    "    w = w - pow(0.1, 5.9)* np.dot(X.T, -2 * (y - np.dot(X, w)))\n",
    "    \n",
    "    if bound - b < 10:\n",
    "        loss = np.power(np.sum(np.power(y - np.dot(w, X.T), 2)), 0.5)\n",
    "        print(loss)\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_0,AMB_TEMP,21,21,20,20,19,19,19,18,17\n",
      "id_0,CH4,1.7,1.7,1.7,1.7,1.7,1.7,1.7,1.7,1.8\n",
      "id_0,CO,0.39,0.36,0.36,0.4,0.53,0.55,0.34,0.31,0.23\n",
      "id_0,NMHC,0.16,0.24,0.22,0.27,0.27,0.26,0.27,0.29,0.1\n",
      "id_0,NO,1.3,1.3,1.3,1.3,1.4,1.6,1.2,1.1,0.9\n",
      "id_0,NO2,17,14,13,14,18,21,8.9,9.4,5\n",
      "id_0,NOx,18,16,14,15,20,23,10,10,5.8\n",
      "id_0,O3,32,31,31,26,16,12,27,20,26\n",
      "id_0,PM10,62,50,44,39,38,32,48,36,25\n",
      "id_0,PM2.5,33,39,39,25,18,18,17,9,4\n",
      "id_0,RAINFALL,NR,NR,NR,NR,NR,NR,NR,NR,NR\n",
      "id_0,RH,83,85,87,87,86,85,78,81,80\n",
      "id_0,SO2,2,1.8,1.8,1.8,2.1,2.6,2,2.3,2.4\n",
      "id_0,THC,1.8,1.9,1.9,2,2,2,2,2,1.9\n",
      "id_0,WD_HR,58,53,67,59,59,73,79,82,104\n",
      "id_0,WIND_DIREC,57,44,73,44,56,115,45,107,103\n",
      "id_0,WIND_SPEED,1.4,1.3,1.5,1.4,1.6,1.6,1.2,1.8,2.3\n",
      "id_0,WS_HR,1,0.9,0.9,0.9,1.2,0.7,1,0.6,1.8\n",
      "id_1,AMB_TEMP,14,13,13,13,13,13,13,12,13\n",
      "id_1,CH4,1.8,1.8,1.8,1.8,1.8,1.8,1.7,1.7,1.8\n",
      "id_1,CO,0.33,0.33,0.33,0.35,0.34,0.33,0.32,0.34,0.61\n",
      "cat: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!cat ./test.csv | head -n 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib import recfunctions as np_rfn\n",
    "\n",
    "\n",
    "def predict(data):\n",
    "    testing_data = to_data(data, fields)\n",
    "    testing_data = (testing_data - norm_mean) / norm_std\n",
    "    p = np.dot(to_X(hours, testing_data, False)[-1], w)\n",
    "    return max(p * y_std + y_mean, 0)\n",
    "\n",
    "\n",
    "with open(\"./test.csv\", \"r\") as f, open(\"./prediction.csv\", \"w\") as out:\n",
    "    current_test_id = \"\"\n",
    "    data = None\n",
    "    \n",
    "    out.write(\"id,value\\n\")\n",
    "\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        test_id, field, raw_values = line.split(\",\", 2)\n",
    "\n",
    "        field = field.replace(\".\", \"\")\n",
    "        dt = np.dtype([(field, np.float64)])\n",
    "        values = [(float(v) if v != \"NR\" else 0) for v in raw_values.split(\",\")]\n",
    "        \n",
    "        if current_test_id != test_id:\n",
    "            if data is not None:\n",
    "                p = predict(data)\n",
    "                out.write(f\"{current_test_id},{p}\\n\")\n",
    "                \n",
    "            current_test_id = test_id\n",
    "            data = np.array(values, dtype=dt)\n",
    "        else:\n",
    "            data = np_rfn.merge_arrays([data, np.array(values, dtype=dt)], flatten=True)\n",
    "\n",
    "    p = predict(data)\n",
    "    out.write(f\"{current_test_id},{p}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_234,24.731843979880026\n",
      "id_235,41.25969992988027\n",
      "id_236,68.50777451687931\n",
      "id_237,42.2697038729074\n",
      "id_238,12.862995317603668\n",
      "id_239,16.859228759444928\n"
     ]
    }
   ],
   "source": [
    "!cat ./prediction.csv | tail -n 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
