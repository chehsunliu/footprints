{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://chehsunliu-mba-2020:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ML2020SpringHW1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11c1c8978>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ML2020SpringHW1\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- metric: string (nullable = true)\n",
      " |-- 0: string (nullable = true)\n",
      " |-- 1: string (nullable = true)\n",
      " |-- 2: string (nullable = true)\n",
      " |-- 3: string (nullable = true)\n",
      " |-- 4: string (nullable = true)\n",
      " |-- 5: string (nullable = true)\n",
      " |-- 6: string (nullable = true)\n",
      " |-- 7: string (nullable = true)\n",
      " |-- 8: string (nullable = true)\n",
      " |-- 9: string (nullable = true)\n",
      " |-- 10: string (nullable = true)\n",
      " |-- 11: string (nullable = true)\n",
      " |-- 12: string (nullable = true)\n",
      " |-- 13: string (nullable = true)\n",
      " |-- 14: string (nullable = true)\n",
      " |-- 15: string (nullable = true)\n",
      " |-- 16: string (nullable = true)\n",
      " |-- 17: string (nullable = true)\n",
      " |-- 18: string (nullable = true)\n",
      " |-- 19: string (nullable = true)\n",
      " |-- 20: string (nullable = true)\n",
      " |-- 21: string (nullable = true)\n",
      " |-- 22: string (nullable = true)\n",
      " |-- 23: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.csv(\"./train.csv\", header=True, encoding=\"big5\")\n",
    "    .drop(\"測站\")\n",
    "    .withColumnRenamed(\"日期\", \"date\")\n",
    "    .withColumnRenamed(\"測項\", \"metric\")\n",
    ")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|    date|    metric|   0|   1|   2|   3|   4|   5|   6|   7|   8|   9|  10|  11|  12|  13|  14|  15|  16|  17|  18|  19|  20|  21|  22|  23|\n",
      "+--------+----------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|2014/1/1|  AMB_TEMP|  14|  14|  14|  13|  12|  12|  12|  12|  15|  17|  20|  22|  22|  22|  22|  22|  21|  19|  17|  16|  15|  15|  15|  15|\n",
      "|2014/1/1|       CH4| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8|\n",
      "|2014/1/1|        CO|0.51|0.41|0.39|0.37|0.35| 0.3|0.37|0.47|0.78|0.74|0.59|0.52|0.41| 0.4|0.37|0.37|0.47|0.69|0.56|0.45|0.38|0.35|0.36|0.32|\n",
      "|2014/1/1|      NMHC| 0.2|0.15|0.13|0.12|0.11|0.06| 0.1|0.13|0.26|0.23| 0.2|0.18|0.12|0.11| 0.1|0.13|0.14|0.23|0.18|0.12| 0.1|0.09| 0.1|0.08|\n",
      "|2014/1/1|        NO| 0.9| 0.6| 0.5| 1.7| 1.8| 1.5| 1.9| 2.2| 6.6| 7.9| 4.2| 2.9| 3.4|   3| 2.5| 2.2| 2.5| 2.3| 2.1| 1.9| 1.5| 1.6| 1.8| 1.5|\n",
      "|2014/1/1|       NO2|  16| 9.2| 8.2| 6.9| 6.8| 3.8| 6.9| 7.8|  15|  21|  14|  11|  14|  12|  11|  11|  22|  28|  19|  12| 8.1|   7| 6.9|   6|\n",
      "|2014/1/1|       NOx|  17| 9.8| 8.7| 8.6| 8.5| 5.3| 8.8| 9.9|  22|  29|  18|  14|  17|  15|  14|  13|  25|  30|  21|  13| 9.7| 8.6| 8.7| 7.5|\n",
      "|2014/1/1|        O3|  16|  30|  27|  23|  24|  28|  24|  22|  21|  29|  44|  58|  50|  57|  65|  64|  51|  34|  33|  34|  37|  38|  38|  36|\n",
      "|2014/1/1|      PM10|  56|  50|  48|  35|  25|  12|   4|   2|  11|  38|  56|  64|  56|  57|  52|  51|  66|  85|  85|  63|  46|  36|  42|  42|\n",
      "|2014/1/1|     PM2.5|  26|  39|  36|  35|  31|  28|  25|  20|  19|  30|  41|  44|  33|  37|  36|  45|  42|  49|  45|  44|  41|  30|  24|  13|\n",
      "|2014/1/1|  RAINFALL|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|  NR|\n",
      "|2014/1/1|        RH|  77|  68|  67|  74|  72|  73|  74|  73|  66|  56|  45|  37|  40|  42|  47|  49|  56|  67|  72|  69|  70|  70|  70|  69|\n",
      "|2014/1/1|       SO2| 1.8|   2| 1.7| 1.6| 1.9| 1.4| 1.5| 1.6| 5.1|  15| 4.5| 2.7| 3.5| 3.6| 3.9| 4.4| 9.9| 5.1| 3.4| 2.3|   2| 1.9| 1.9| 1.9|\n",
      "|2014/1/1|       THC|   2|   2|   2| 1.9| 1.9| 1.8| 1.9| 1.9| 2.1|   2|   2|   2| 1.9| 1.9| 1.9| 1.9| 1.9| 2.1|   2| 1.9| 1.9| 1.9| 1.9| 1.9|\n",
      "|2014/1/1|     WD_HR|  37|  80|  57|  76| 110| 106| 101| 104| 124|  46| 241| 280| 297| 305| 307| 304| 307| 124| 118| 121| 113| 112| 106| 110|\n",
      "|2014/1/1|WIND_DIREC|  35|  79| 2.4|  55|  94| 116| 106|  94| 232| 153| 283| 269| 290| 316| 313| 305| 291| 124| 119| 118| 114| 108| 102| 111|\n",
      "|2014/1/1|WIND_SPEED| 1.4| 1.8|   1| 0.6| 1.7| 2.5| 2.5|   2| 0.6| 0.8| 1.6| 1.9| 2.1| 3.3| 2.5| 2.2| 1.4| 2.2| 2.8|   3| 2.6| 2.7| 2.1| 2.1|\n",
      "|2014/1/1|     WS_HR| 0.5| 0.9| 0.6| 0.3| 0.6| 1.9|   2|   2| 0.5| 0.3| 0.8| 1.2|   2| 2.6| 2.1| 2.1| 1.9|   1| 2.5| 2.5| 2.8| 2.6| 2.4| 2.3|\n",
      "|2014/1/2|  AMB_TEMP|  16|  15|  15|  14|  14|  15|  16|  16|  17|  20|  22|  23|  24|  24|  24|  24|  23|  21|  20|  19|  18|  18|  18|  18|\n",
      "|2014/1/2|       CH4| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.7| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8| 1.8|\n",
      "+--------+----------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- metric: string (nullable = true)\n",
      " |-- value: float (nullable = true)\n",
      "\n",
      "+----------+----+--------+-----+\n",
      "|      date|hour|  metric|value|\n",
      "+----------+----+--------+-----+\n",
      "|2014-01-01|   0|AMB_TEMP| 14.0|\n",
      "|2014-01-01|   1|AMB_TEMP| 14.0|\n",
      "|2014-01-01|   2|AMB_TEMP| 14.0|\n",
      "|2014-01-01|   3|AMB_TEMP| 13.0|\n",
      "|2014-01-01|   4|AMB_TEMP| 12.0|\n",
      "|2014-01-01|   5|AMB_TEMP| 12.0|\n",
      "|2014-01-01|   6|AMB_TEMP| 12.0|\n",
      "|2014-01-01|   7|AMB_TEMP| 12.0|\n",
      "|2014-01-01|   8|AMB_TEMP| 15.0|\n",
      "|2014-01-01|   9|AMB_TEMP| 17.0|\n",
      "+----------+----+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r = (\n",
    "    df\n",
    "    .selectExpr(\n",
    "        \"to_date(date, 'yyyy/MM/dd') as date\",\n",
    "        \"metric\",\n",
    "        \"\"\"\n",
    "        explode(\n",
    "          arrays_zip(\n",
    "            array(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23),\n",
    "            array(`0`,`1`,`2`,`3`,`4`,`5`,`6`,`7`,`8`,`9`,`10`,`11`,`12`,`13`,`14`,`15`,`16`,`17`,`18`,`19`,`20`,`21`,`22`,`23`)\n",
    "          )\n",
    "        ) as value\n",
    "        \"\"\",\n",
    "    )\n",
    "    .selectExpr(\n",
    "        \"date\",\n",
    "        \"value.`0` as hour\",\n",
    "        \"metric\",\n",
    "        \"value.`1` as value\",\n",
    "    )\n",
    "    .selectExpr(\n",
    "        \"date\",\n",
    "        \"hour\",\n",
    "        \"metric\",\n",
    "        \"\"\"case\n",
    "        when value = 'NR' then\n",
    "          null\n",
    "        else\n",
    "          float(value)\n",
    "        end as value\"\"\",\n",
    "    )\n",
    ")\n",
    "df_r.printSchema()\n",
    "df_r.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+\n",
      "|    metric|min_value|max_value|\n",
      "+----------+---------+---------+\n",
      "|  AMB_TEMP|    -12.3|     36.0|\n",
      "|       CH4|     -0.2|      2.0|\n",
      "|        CO|    -0.12|     7.57|\n",
      "|      NMHC|      0.0|      1.3|\n",
      "|        NO|     -1.1|     31.0|\n",
      "|       NO2|      0.0|     46.0|\n",
      "|       NOx|     -2.4|     71.0|\n",
      "|        O3|      0.0|    231.0|\n",
      "|      PM10|      0.0|    181.0|\n",
      "|     PM2.5|     -1.0|    112.0|\n",
      "|  RAINFALL|      0.0|     74.0|\n",
      "|        RH|     29.0|     99.0|\n",
      "|       SO2|     -1.6|     22.0|\n",
      "|       THC|     -0.2|      3.0|\n",
      "|     WD_HR|      0.1|    360.0|\n",
      "|WIND_DIREC|      0.0|    360.0|\n",
      "|WIND_SPEED|      0.0|      7.7|\n",
      "|     WS_HR|      0.0|      7.0|\n",
      "+----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fns\n",
    "\n",
    "(\n",
    "    df_r.groupBy(\"metric\")\n",
    "    .agg(\n",
    "        fns.min(\"value\").alias(\"min_value\"),\n",
    "        fns.max(\"value\").alias(\"max_value\"),\n",
    "    )\n",
    "    .orderBy(\"metric\").show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
